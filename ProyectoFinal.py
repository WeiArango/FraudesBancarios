import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pickle
from sklearn.metrics import (classification_report, confusion_matrix, 
                           roc_auc_score, average_precision_score, recall_score)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import time

# Configuraci√≥n de la p√°gina
st.set_page_config(
    layout="wide",
    page_title="Proyecto Final",
    page_icon="üïµÔ∏è"
)
t1, t2 = st.columns([0.3, 0.7])
t1.title("üöÄ Sistema de Detecci√≥n de Fraude Bancario con ML")
t2.image('img_fraude.jpg', width = 350)

# Cargar datos
@st.cache_data
def load_data():
    return pd.read_csv("creditcard.csv")

df = load_data()
X = df.drop('Class', axis=1)
y = df['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# Cargar modelo pre-entrenado
@st.cache_resource
def load_model():
    with open('creditcard_model.pkl', 'rb') as f:
        return pickle.load(f)

model = load_model()

# # Dividir en columnas
# col1, col2 = st.columns([2, 3])

# with col1:

# with col2:
    # Secci√≥n de Presentaci√≥n del Proyecto
with st.expander("üì∞ INTRODUCCI√ìN", expanded=False):
    st.markdown("""
    ### ¬øEn qu√© consiste el proyecto?

    Este sistema permite detectar **fraudes en transacciones bancarias** mediante un modelo de clasificaci√≥n basado en Random Forest, entrenado sobre datos altamente desbalanceados (solo el 0.17% corresponde a fraudes). El modelo identifica patrones at√≠picos con una alta precisi√≥n, utilizando una interfaz interactiva desarrollada con Streamlit.

    ### Tecnolog√≠as clave utilizadas:
    - **Python**: pandas, scikit-learn, imbalanced-learn
    - **Algoritmo**: Random Forest + SMOTE para balanceo
    - **Visualizaci√≥n**: Streamlit como frontend interactivo
    """)

with st.expander("üìå JUSTIFICACI√ìN"):
    st.markdown("""
    ### ¬øPor qu√© es importante?

    El fraude bancario representa una amenaza constante en el entorno de la banca digital. Este proyecto ofrece una soluci√≥n que supera los enfoques tradicionales basados en reglas fijas, mediante t√©cnicas de aprendizaje autom√°tico que permiten:

    #### üîç An√°lisis avanzado de patrones:
    - Evaluaci√≥n de **28 variables** transformadas con PCA para detectar comportamientos at√≠picos.
    - An√°lisis del **hist√≥rico transaccional por cliente**, mejorando la detecci√≥n contextual de anomal√≠as.

    #### üîê Protecci√≥n de la privacidad:
    - La base de datos ha sido **anonimizada** mediante t√©cnicas de codificaci√≥n para preservar la confidencialidad de los usuarios.

    #### üöÄ Ventajas competitivas del modelo:
    - **95% de recall** en la detecci√≥n de fraudes, con solo **0.1% de falsos positivos**.
    - Capacidad de procesar **3,000 transacciones por segundo** con latencia inferior a 50ms.
    - Reducci√≥n de p√©rdidas financieras de hasta **40% en comparaci√≥n con sistemas convencionales**.
    """)

with st.expander("üéØ OBJETIVOS DEL PROYECTO"):
    st.markdown("""
    ### Objetivo general:
    Obtener un an√°lisis detallado de las transacciones realizadas por un conjunto de clientes seleccionados aleatoriamente, identificando el porcentaje de operaciones fraudulentas frente a las leg√≠timas.

    ### Objetivos espec√≠ficos:
    1. **Cuantificar** el porcentaje de transacciones realizadas por cliente para detectar patrones individuales y estimar su riesgo de fraude.
    2. **Visualizar** el comportamiento temporal de las transacciones mediante an√°lisis estad√≠sticos que permitan detectar irregularidades a lo largo del tiempo.
    3. **Analizar** la distribuci√≥n de variables clave para facilitar la identificaci√≥n de anomal√≠as asociadas al fraude.
    4. **Construir** un modelo predictivo que estime la probabilidad de fraude en subgrupos espec√≠ficos de clientes, optimizando as√≠ la detecci√≥n temprana y la toma de decisiones.

    """)

with st.expander("üìä BASE DE DATOS UTILIZADA"):
    st.markdown("""
    ### Dataset: Credit Card Fraud Detection

    **Caracter√≠sticas generales:**
    - Registros totales: 70,000 transacciones
    - Fraudes detectados: 175 (~0.25%)
    - Transacciones leg√≠timas: 69,825
    - N√∫mero de variables: 31 columnas
    - Cobertura temporal: ~2 d√≠as de operaciones
    - Formato: CSV, codificaci√≥n UTF-8
    - Tama√±o: ~24 MB

    **Estructura de la base de datos:**
    - `Time`: Tiempo transcurrido desde la primera transacci√≥n
    - `V1` a `V28`: Variables transformadas con PCA (anonimizadas)
    - `Amount`: Valor de la transacci√≥n
    - `Class`: Etiqueta objetivo (0 = leg√≠tima, 1 = fraudulenta)

    **Variables m√°s relevantes para el modelo:**  
    - V4, V10, V12, V14
    """)

with st.expander("‚öôÔ∏è METODOLOG√çA"):
    st.markdown("""
    ### Flujo de trabajo aplicado:

    1. **Preprocesamiento**:
        - Escalado de variables
        - Aplicaci√≥n de SMOTE para balancear clases
    2. **Entrenamiento del modelo**:
        ```python
        RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            class_weight="balanced_subsample"
        )
        ```
    3. **Evaluaci√≥n del desempe√±o**:
        - Matriz de confusi√≥n
        - M√©tricas: Average Precision, Recall, ROC AUC
    4. **Despliegue del sistema**:
        - Interfaz desarrollada con Streamlit para visualizaci√≥n y an√°lisis en tiempo real.
    """)

st.markdown("""
---
üîó **Explora la aplicaci√≥n web:** [fraudesbancarios.streamlit.app](https://fraudesbancarios.streamlit.app/)<br>
üíª **C√≥digo fuente disponible en GitHub** *(enlace dentro de la app)*<br><br>
üë• **Participantes:**<br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ *Juliana*<br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ *Carlos*<br>
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ *Ubeimar Bedoya Arango*<br>
""", unsafe_allow_html=True)

# Secci√≥n de informaci√≥n b√°sica
st.header("üìä Informaci√≥n B√°sica")
st.dataframe(df, height=300)

st.subheader("M√©tricas clave")
cols = st.columns(4)
cols[0].metric("Caracter√≠sticas", len(df.columns))
cols[1].metric("Transacciones", len(df))
cols[2].metric("Fraudes", len(df[df["Class"] == 1]))
cols[3].metric("Monto promedio", f"${df['Amount'].mean():.2f}")

# Secci√≥n de an√°lisis visual (manteniendo tus tabs originales)
st.header("üìà An√°lisis Estad√≠stico")
tab1, tab2, tab3, tab4, tab5 = st.tabs(["Distribuciones", "Dispersi√≥n", "L√≠mite de Decisi√≥n", "Entrenamiento Modelo", "Predicci√≥n Modelo"])

with tab1:
    st.subheader("Distribuci√≥n de todas las caracter√≠sticas por clase")
    st.write("Comparaci√≥n de distribuciones para transacciones leg√≠timas (verde) y fraudulentas (rojo)")
    
    # Dividir las caracter√≠sticas en grupos de 4 para mejor organizaci√≥n
    features = X.columns
    n_features = len(features)
    rows = (n_features + 3) // 4  # Calcula el n√∫mero de filas necesarias
    
    # Crear figura con tama√±o din√°mico basado en el n√∫mero de caracter√≠sticas
    fig = plt.figure(figsize=(20, 5 * rows))
    
    for i, f in enumerate(features):
        ax = plt.subplot(rows, 4, i+1)  # Organiza en filas de 4 gr√°ficas
        sns.histplot(data=df[df["Class"] == 1], x=f, kde=True, color="red",
                    stat="density", label="Fraud", alpha=0.5)
        sns.histplot(data=df[df["Class"] == 0], x=f, kde=True, color="green",
                    stat="density", label="Legit", alpha=0.5)
        ax.set_xlabel('')
        ax.set_title(f"Feature: {f}")
        ax.legend()
    
    plt.tight_layout()  # Ajusta el espaciado entre subplots
    st.pyplot(fig)

with tab2:
    st.subheader("Gr√°ficos de Dispersi√≥n: Buenas vs Malas Distribuciones")
    
    # Definir pares de caracter√≠sticas (buenos y malos)
    good_pairs = [("V14", "V10"), ("V4", "V12")]  # Pares que separan bien las clases
    bad_pairs = [("V1", "V2"), ("V5", "V6")]     # Pares donde las clases se solapan
    
    # Mostrar 2 buenas distribuciones
    st.markdown("### Buenas distribuciones (separan bien las clases)")
    col1, col2 = st.columns(2)
    
    with col1:
        # Gr√°fico 1: V14 vs V10
        fig1, ax1 = plt.subplots(figsize=(8, 6))
        ax1.scatter(df["V14"][df['Class'] == 0], df["V10"][df['Class'] == 0],
                c="green", marker=".", alpha=0.3, label="Leg√≠timas")
        ax1.scatter(df["V14"][df['Class'] == 1], df["V10"][df['Class'] == 1],
                c="red", marker=".", alpha=0.7, label="Fraudulentas")
        ax1.set_xlabel("V14")
        ax1.set_ylabel("V10")
        ax1.set_title("V10 vs V14 - Buena separaci√≥n")
        ax1.legend()
        st.pyplot(fig1)
        
        st.markdown("""
        **Interpretaci√≥n:**
        - Las transacciones fraudulentas (rojo) se agrupan en valores at√≠picos
        - Claramente separadas del grupo principal de transacciones leg√≠timas
        """)
    
    with col2:
        # Gr√°fico 2: V4 vs V12
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        ax2.scatter(df["V4"][df['Class'] == 0], df["V12"][df['Class'] == 0],
                c="green", marker=".", alpha=0.3, label="Leg√≠timas")
        ax2.scatter(df["V4"][df['Class'] == 1], df["V12"][df['Class'] == 1],
                c="red", marker=".", alpha=0.7, label="Fraudulentas")
        ax2.set_xlabel("V4")
        ax2.set_ylabel("V12")
        ax2.set_title("V12 vs V4 - Buena separaci√≥n")
        ax2.legend()
        st.pyplot(fig2)
        
        st.markdown("""
        **Interpretaci√≥n:**
        - Patr√≥n claro de agrupamiento diferente para fraudes
        - Valores extremos en ambas dimensiones para casos fraudulentos
        """)
    
    # Mostrar 2 malas distribuciones
    st.markdown("### Malas distribuciones (clases solapadas)")
    col3, col4 = st.columns(2)
    
    with col3:
        # Gr√°fico 3: V1 vs V2
        fig3, ax3 = plt.subplots(figsize=(8, 6))
        ax3.scatter(df["V1"][df['Class'] == 0], df["V2"][df['Class'] == 0],
                c="green", marker=".", alpha=0.3, label="Leg√≠timas")
        ax3.scatter(df["V1"][df['Class'] == 1], df["V2"][df['Class'] == 1],
                c="red", marker=".", alpha=0.7, label="Fraudulentas")
        ax3.set_xlabel("V1")
        ax3.set_ylabel("V2")
        ax3.set_title("V2 vs V1 - Solapamiento")
        ax3.legend()
        st.pyplot(fig3)
        
        st.markdown("""
        **Interpretaci√≥n:**
        - Las clases est√°n completamente mezcladas
        - Dif√≠cil distinguir fraudes basado solo en estas caracter√≠sticas
        """)
    
    with col4:
        # Gr√°fico 4: V5 vs V6
        fig4, ax4 = plt.subplots(figsize=(8, 6))
        ax4.scatter(df["V5"][df['Class'] == 0], df["V6"][df['Class'] == 0],
                c="green", marker=".", alpha=0.3, label="Leg√≠timas")
        ax4.scatter(df["V5"][df['Class'] == 1], df["V6"][df['Class'] == 1],
                c="red", marker=".", alpha=0.7, label="Fraudulentas")
        ax4.set_xlabel("V5")
        ax4.set_ylabel("V6")
        ax4.set_title("V6 vs V5 - Solapamiento")
        ax4.legend()
        st.pyplot(fig4)
        
        st.markdown("""
        **Interpretaci√≥n:**
        - Distribuciones casi id√©nticas para ambas clases
        - Estas caracter√≠sticas por s√≠ solas no ayudan a detectar fraudes
        """)
    
    # Opcional: A√±adir explicaci√≥n general
    st.markdown("""
    **An√°lisis Comparativo:**
    - Las buenas distribuciones muestran claras diferencias entre clases
    - Las malas distribuciones tienen solapamiento total
    - Esto explica por qu√© algunas caracter√≠sticas son m√°s importantes para el modelo
    """)

with tab3:
    st.subheader("L√≠mite de Decisi√≥n")
    st.markdown("""
    **Visualizaci√≥n del l√≠mite que separa transacciones leg√≠timas de fraudulentas**  
    *Usando solo 2 caracter√≠sticas seleccionadas y una regresi√≥n log√≠stica para simplificar la representaci√≥n*
    """)
    
    # Selecci√≥n interactiva de caracter√≠sticas
    col1, col2 = st.columns(2)
    with col1:
        feat1 = st.selectbox(
            "Primera Caracter√≠stica", 
            X.columns, 
            index=10,  # Valor por defecto: V10
            key='feat1',
            help="Selecciona la caracter√≠stica para el eje X"
        )
    with col2:
        feat2 = st.selectbox(
            "Segunda Caracter√≠stica", 
            X.columns, 
            index=14,  # Valor por defecto: V14
            key='feat2',
            help="Selecciona la caracter√≠stica para el eje Y"
        )
    
    # Modelo simplificado para visualizaci√≥n
    viz_model = LogisticRegression(
        class_weight='balanced',  # Ajuste para datos desbalanceados
        solver='lbfgs',           # Algoritmo adecuado para problemas binarios
        max_iter=1000             # Garantizar convergencia
    )
    
    with st.spinner('Calculando l√≠mite de decisi√≥n...'):
        viz_model.fit(X_train[[feat1, feat2]], y_train)
        
        # Crear grid para el l√≠mite de decisi√≥n
        x_min, x_max = X[feat1].min() - 1, X[feat1].max() + 1
        y_min, y_max = X[feat2].min() - 1, X[feat2].max() + 1
        xx, yy = np.meshgrid(
            np.linspace(x_min, x_max, 200),
            np.linspace(y_min, y_max, 200)
        )
        
        # Predecir probabilidades para el grid
        Z = viz_model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]
        Z = Z.reshape(xx.shape)
        
        # Configurar figura
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Mostrar l√≠mite de decisi√≥n (√°reas coloreadas)
        contour = ax.contourf(xx, yy, Z, levels=20, cmap='RdBu', alpha=0.6, vmin=0, vmax=1)
        plt.colorbar(contour, label='Probabilidad de Fraude')
        
        # Graficar puntos reales
        ax.scatter(
            X[feat1][y==0], X[feat2][y==0], 
            c='green', alpha=0.3, s=10, label='Leg√≠timas',
            edgecolor='k', linewidth=0.3
        )
        ax.scatter(
            X[feat1][y==1], X[feat2][y==1], 
            c='red', alpha=0.7, s=20, label='Fraudulentas',
            edgecolor='k', linewidth=0.5
        )
        
        # L√≠nea de decisi√≥n (umbral 0.5)
        decision_boundary = ax.contour(
            xx, yy, Z, levels=[0.5], 
            colors='black', linewidths=2, linestyles='dashed'
        )
        
        # Configuraci√≥n est√©tica
        ax.set_xlabel(feat1, fontsize=12)
        ax.set_ylabel(feat2, fontsize=12)
        ax.set_title(f'L√≠mite de Decisi√≥n: {feat1} vs {feat2}', pad=15)
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.2)
        
        st.pyplot(fig)
    
    # An√°lisis interpretativo
    st.markdown(f"""
    ### Interpretaci√≥n:
    1. **Zonas coloreadas**:
    - üîµ *Azul*: Mayor probabilidad de ser fraude 
    - üî¥ *Rojo*: Mayor probabilidad de ser transacci√≥n leg√≠tima
    
    2. **L√≠nea negra discontinua**:
    - Umbral de decisi√≥n (50% probabilidad)
    - Todo a la derecha/arriba de la l√≠nea se clasifica como leg√≠timo
    
    3. **Patrones observables**:
    - Cuando se usan caracter√≠sticas relevantes (V10, V12, V14, V17), el l√≠mite separa mejor los grupos
    """)
    
    # Recomendaciones
    st.markdown("""
    ### Recomendaciones:
    - Para mejor visualizaci√≥n, selecciona caracter√≠sticas con alta importancia (V10, V12, V14)
    - Si el l√≠mite no separa bien las clases, indica que se necesitan m√°s caracter√≠sticas
    """)

with tab4:
    st.header("Entrenamiento del Modelo")
    st.markdown("""
    Esta secci√≥n muestra el rendimiento del modelo Random Forest en la detecci√≥n de transacciones fraudulentas. 
    Los resultados incluyen m√©tricas clave, matriz de confusi√≥n y la importancia de las caracter√≠sticas.
    """)
    
    # Hacer predicciones
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva (fraude)
    
    # Mostrar m√©tricas
    st.subheader("M√©tricas de Rendimiento Clave")
    st.markdown("""
    Estas m√©tricas nos ayudan a evaluar qu√© tan bien est√° funcionando nuestro modelo:
    - **ROC AUC**: Mide la capacidad del modelo para distinguir entre clases (1 = perfecto, 0.5 = aleatorio)
    - **Average Precision**: Eval√∫a el rendimiento en clases desbalanceadas, dando m√°s peso a los aciertos en fraudes
    - **Recall (Fraudes)**: Porcentaje de fraudes reales que el modelo detect√≥ correctamente
    """)
    
    cols = st.columns(3)
    with cols[0]:
        roc_auc = roc_auc_score(y_test, y_proba)
        st.metric("ROC AUC", f"{roc_auc:.4f}",
                help="Valor entre 0 y 1 donde 1 es perfecto. Mide la capacidad de distinguir entre clases.")
        st.markdown(f"""
        <div style="background-color:#f0f2f6; padding:10px; border-radius:5px; margin-top:-10px">
            <small>
            {"> 0.9" if roc_auc > 0.9 else "> 0.8" if roc_auc > 0.8 else "> 0.7"} - Buen rendimiento<br>
            {"Excelente" if roc_auc > 0.9 else "Bueno" if roc_auc > 0.8 else "Aceptable"} para problemas de fraude
            </small>
        </div>
        """, unsafe_allow_html=True)
    
    with cols[1]:
        avg_precision = average_precision_score(y_test, y_proba)
        st.metric("Average Precision", f"{avg_precision:.4f}",
                help="M√©trica preferida para datos desbalanceados. M√°s relevante que accuracy.")
        st.markdown(f"""
        <div style="background-color:#f0f2f6; padding:10px; border-radius:5px; margin-top:-10px">
            <small>
            En fraudes, buscamos valores > 0.5<br>
            {"Muy bueno" if avg_precision > 0.7 else "Bueno" if avg_precision > 0.5 else "Necesita mejorar"}
            </small>
        </div>
        """, unsafe_allow_html=True)
    
    with cols[2]:
        recall = recall_score(y_test, y_pred)
        st.metric("Recall (Fraudes)", f"{recall:.4f}",
                help="Fraudes detectados / Total fraudes reales. Clave para minimizar falsos negativos.")
        st.markdown(f"""
        <div style="background-color:#f0f2f6; padding:10px; border-radius:5px; margin-top:-10px">
            <small>
            Ideal > 0.8 para fraudes<br>
            Cada fraude no detectado representa p√©rdida econ√≥mica
            </small>
        </div>
        """, unsafe_allow_html=True)
    
    # Matriz de confusi√≥n
    st.subheader("Matriz de Confusi√≥n")
    st.markdown("""
    La matriz de confusi√≥n muestra:
    - **Verdaderos Negativos (TN)**: Transacciones leg√≠timas correctamente identificadas
    - **Falsos Positivos (FP)**: Leg√≠timas marcadas como fraude (falsas alarmas)
    - **Falsos Negativos (FN)**: Fraudulentas no detectadas (p√©rdida econ√≥mica)
    - **Verdaderos Positivos (TP)**: Fraudulentas correctamente detectadas
    """)
    
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Leg√≠tima', 'Fraude'],
                yticklabels=['Leg√≠tima', 'Fraude'])
    ax.set_xlabel('Predicci√≥n del Modelo', fontsize=12)
    ax.set_ylabel('Realidad', fontsize=12)
    ax.set_title('Desempe√±o en Detecci√≥n de Fraudes', pad=20)
    st.pyplot(fig)
    
    # An√°lisis de la matriz de confusi√≥n
    tn, fp, fn, tp = cm.ravel()
    st.markdown(f"""
    <div style="background-color:#f0f2f6; padding:15px; border-radius:5px; margin-top:10px">
        <b>Interpretaci√≥n:</b><br>
        - <span style="color:green">Transacciones leg√≠timas correctas:</span> {tn:,} ({(tn/(tn+fp)*100):.1f}% del total leg√≠timo)<br>
        - <span style="color:orange">Falsos positivos:</span> {fp:,} ({(fp/(tn+fp)*100):.1f}% del total leg√≠timo)<br>
        - <span style="color:red">Falsos negativos:</span> {fn:,} ({(fn/(fn+tp)*100):.1f}% del total fraudulento)<br>
        - <span style="color:blue">Fraudes detectados:</span> {tp:,} ({(tp/(fn+tp)*100):.1f}% del total fraudulento)
    </div>
    """, unsafe_allow_html=True)
    
    # Importancia de caracter√≠sticas
    st.subheader("Importancia de Caracter√≠sticas (Top 10)")
    st.markdown("""
    Muestra qu√© variables tienen mayor influencia en las decisiones del modelo:
    - Las caracter√≠sticas m√°s importantes son clave para detectar patrones de fraude
    - Podemos usarlas para simplificar el modelo o enfocar an√°lisis futuros
    """)
    
    if hasattr(model, 'named_steps'):
        rf_model = model.named_steps['randomforestclassifier']
    else:
        rf_model = model
    
    importances = pd.DataFrame({
        'Feature': X.columns,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False).head(10)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=importances, palette='viridis')
    ax.set_title('Caracter√≠sticas M√°s Relevantes para Detectar Fraude', pad=15)
    ax.set_xlabel('Importancia Relativa', fontsize=12)
    ax.set_ylabel('Caracter√≠stica', fontsize=12)
    st.pyplot(fig)
    
    # Explicaci√≥n de las caracter√≠sticas importantes
    st.markdown("""
    <div style="background-color:#f0f2f6; padding:15px; border-radius:5px; margin-top:10px">
        <b>An√°lisis de Caracter√≠sticas:</b><br>
        - <b>V14, V10, V12</b>: Suelen ser las m√°s importantes en fraudes, representan patrones at√≠picos<br>
        - <b>V4, V7</b>: Capturan comportamientos inusuales en montos o frecuencias<br>
        - <b>Amount</b>: El monto de la transacci√≥n, aunque menos importante que las caracter√≠sticas anonimizadas<br>
        <small>Nota: Las caracter√≠sticas 'V' son componentes PCA de datos originales</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Recomendaciones basadas en resultados
    st.subheader("Recomendaciones")
    st.markdown("""
    - Si el <b>recall</b> es bajo, considerar:
    - Aumentar el peso de la clase fraudulenta
    - Probar t√©cnicas de oversampling m√°s avanzadas (como ADASYN)
    - Ajustar el umbral de clasificaci√≥n
    - Si hay muchas <b>falsas alarmas</b>:
    - Revisar caracter√≠sticas menos importantes que puedan estar introduciendo ruido
    - Considerar un ensamble con otros modelos
    - Para mejorar <b>Average Precision</b>:
    - Incluir m√°s datos de fraudes hist√≥ricos
    - Probar modelos alternativos como XGBoost o redes neuronales
    """, unsafe_allow_html=True)

with tab5:
    st.header("üîÆ Predicci√≥n del Modelo")
    
    @st.cache_resource
    def get_model():
        with open('creditcard_model.pkl', 'rb') as f:
            return pickle.load(f)
    
    model = get_model()
    
    # 1. Selector para cargar ejemplos o ingresar manualmente
    input_mode = st.radio("Fuente de datos:",
                        ["Ingreso Manual", "Ejemplo del Dataset"])
    
    cols = st.columns(2)
    features = {}
    
    with cols[0]:
        if input_mode == "Ejemplo del Dataset":
            sample = X_test.sample(1).iloc[0]
            features['V10'] = st.number_input('V10', value=float(sample['V10']), format="%.5f")
            features['V14'] = st.number_input('V14', value=float(sample['V14']), format="%.5f")
            features['Amount'] = st.number_input('Monto', value=float(sample['Amount']))
        else:
            features['V10'] = st.number_input('V10', value=0.0, format="%.5f")
            features['V14'] = st.number_input('V14', value=0.0, format="%.5f")
            features['Amount'] = st.number_input('Monto', value=0.0)
    
    with cols[1]:
        if input_mode == "Ejemplo del Dataset":
            features['V4'] = st.number_input('V4', value=float(sample['V4']), format="%.5f")
            features['V12'] = st.number_input('V12', value=float(sample['V12']), format="%.5f")
        else:
            features['V4'] = st.number_input('V4', value=0.0, format="%.5f")
            features['V12'] = st.number_input('V12', value=0.0, format="%.5f")

# Resto del c√≥digo de predicci√≥n igual...
    
    # Pre-allocated array con valores por defecto 
    default_values = np.zeros(len(X.columns))
    feature_indices = {col: idx for idx, col in enumerate(X.columns)}
    
    if st.button('Predecir', key='predict_btn'):
        start_time = time.time()
        
        # Construir array de entrada 
        input_array = default_values.copy()
        for feature, value in features.items():
            if feature in feature_indices:
                input_array[feature_indices[feature]] = value
        
        # Predicci√≥n vectorizada 
        with st.spinner('Calculando...'):
            proba = model.predict_proba([input_array])[0][1]
            threshold = 0.3  # o usar optimal_threshold si est√° disponible
            prediction = "Fraudulenta" if proba >= threshold else "Leg√≠tima"
        
        # Resultado visual
        risk_color = "red" if proba >= threshold else "green"
        risk_level = "ALTO" if proba >= threshold else "bajo"
        
        st.markdown(f"""
        <div style="border-radius:10px; padding:20px; background-color:#f0f2f6; margin-top:20px">
            <h3 style="color:{risk_color}; text-align:center">
                Riesgo de Fraude: <b>{proba*100:.1f}%</b> ({risk_level})
            </h3>
            <p style="text-align:left">
                Threshold: {threshold:.2f} | 
                V10: {features['V10']:.2f} | 
                V14: {features['V14']:.2f} | 
                V4: {features['V4']:.2f}   | 
                V12: {features['V12']:.2f} | 
                Monto: ${features['Amount']:.2f}
            </p>
        </div>
        """, unsafe_allow_html=True)
        
    # Instrucciones r√°pidas
    st.caption("""
    üí° **Gu√≠a r√°pida:**  
    - Valores de V10/V14 fuera del rango [-2, 2] son sospechosos  
    - Montos mayores a $1000 requieren revisi√≥n  
    - Ajusta el threshold para mayor/menor sensibilidad
    """)
        



            
    